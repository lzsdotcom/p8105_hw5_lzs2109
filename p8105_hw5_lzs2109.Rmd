---
title: "Data Science I Homework 5 - lzs2109"
author: "Louis Sharp"
date: "11/11/2021"
output: github_document
---

```{r, message = F}
library(tidyverse)
```


### Problem 1

```{r}
homicide_df = read_csv("./data/homicide-data.csv") %>% 
  mutate(city_state = str_c(city, state, sep = ", "),
         status = ifelse(disposition == "Closed by arrest", "solved", "unsolved"))
```

The raw data from homicide-data.csv contains the variables `r names(homicide_df)`, which give ID numbers to each homicide, in addition to the date, victim's information, the location (city, state, and specific latitude/longitude) of the homicide, and finally the status of the case (closed/open/arrest/no arrest). There are 51 cities and a total of `r nrow(homicide_df)` homicides with data included in the dataset.

```{r}
homicide_df %>% 
  group_by(city_state, status) %>% 
  count()

bmore = 
  homicide_df %>%
  filter(city_state == "Baltimore, MD") %>%
  group_by(status) %>% 
  count() %>% 
  pivot_wider(names_from = "status", values_from = "n") %>% 
  mutate(total = sum(solved, unsolved))

bmore = prop.test(x = pull(bmore, unsolved), n = pull(bmore, total))

bmore %>% 
  broom::tidy() %>% 
  select(estimate, starts_with("conf"))
```

There's the Baltimore, MD proportion of unsolved homicides, along with lower and upper confidence intervals. We'll use that code above in a more general form to make a function that can calculate this with any city in the homicide_df dataframe below.

```{r}
unsolved_murders = function(location) {
  
  city = homicide_df %>% 
           filter(city_state == location) %>%
           group_by(status) %>% 
           count() %>% 
           pivot_wider(names_from = "status", values_from = "n") %>% 
           mutate(total = sum(solved, unsolved))
  
  city = prop.test(x = pull(city, unsolved), n = pull(city, total))
  
  city %>% 
    broom::tidy() %>% 
    select(estimate, starts_with("conf"))
  
}

#unsolved_murders("Atlanta, GA")
#unsolved_murders("San Francisco, CA")
```

There's the function, with a couple of tests commented out just to make sure it works on any given city in the data set. Now that we've done that, we need a list of all the cities in the data set that have the appropriate data so that we can iterate over that list of cities and get the same info for all of them in one call. Instead of having a vector just hanging out, we can nest the original homicide_df. Also, we'll have to remove Tulsa, AL as it did not have appropriate data (1 solved, no unsolved) which broke the prop.test() function.

```{r}
unsolved_murders_df = 
  homicide_df %>% 
  nest(homicide_data = -city_state) %>% 
  filter(city_state != "Tulsa, AL") %>% 
  mutate(prop_unsolved = map(city_state, unsolved_murders)) %>% 
  select(-homicide_data) %>% 
  unnest(prop_unsolved)
  
head(unsolved_murders_df)

unsolved_murders_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate, color = city_state)) +
  geom_point() +
  geom_errorbar(aes(x = city_state, ymin = conf.low, ymax = conf.high)) +
  labs(title = "Proportion of Unsolved Murders by City and State",
       x = "City and State",
       y = "Proportion of Unsolved Murders") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  theme(legend.position = "none")
```


## Problem 2

```{r, message = F, warning = F}
hw5_df = 
  tibble(
  filenames = list.files("data/hw5_data/"),
  location = str_c("./data/hw5_data/", filenames),
  data = map(location, read_csv)
) %>% 
  mutate(filenames = str_remove(filenames, ".csv$")) %>% 
  rename(treatment = filenames) %>% 
  unnest() %>% 
  pivot_longer(week_1:week_8, 
               names_to = "week", 
               names_prefix = "week_", 
               values_to = "data_value") %>% 
  mutate(week = as.numeric(week),
         group = ifelse(str_detect(treatment, "^con"), "control", "treatment"),
         subject_id = str_remove(treatment, "^con_"),
         subject_id = str_remove(subject_id, "^exp_")) %>% 
  select(treatment, subject_id, group, week, data_value)
  

hw5_df %>% 
  ggplot(aes(x = week, y = data_value, color = group)) +
  geom_line(aes(group = treatment), alpha = 0.6)
```

Based on the spaghetti plot, we can see that by the end of week 8, all subjects in the control arm have a lower data value than all subjects in the treatment group. If the treatment was meant to increase the data value, it appears to be effective in all subjects, including those that had lower starting data values than subjects in the control group.


## Problem 3

```{r}
library(tidyverse)

set.seed(10)

iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species))
```

Function that takes a vector and replaces missing values below.

```{r}
#vec_char = c("douglasiana", "innominata", "macrosiphon", NA, NA, "tenax", NA)
#vec_num = c(3, 7, 23, NA, 74, NA, 52, NA, NA)

na_replacer = function(vec) {
  
  if (is.character(vec)) {
    vec = replace_na(vec, "virginica")
  } else if (is.numeric(vec)) {
    vec = replace_na(vec, mean(vec, na.rm = TRUE))
  }
  vec
}

#na_replacer(vec_char) #testing function on character vector
#na_replacer(vec_num) #testing function on numeric vector 
```

Some examples testing the function commented out in the above code chunk. Now we'll map this function over the columns of iris_with_missing data frame.

```{r}
iris_without_missing = 
  map(iris_with_missing, na_replacer) %>% 
  as.data.frame()
head(iris_without_missing, 12)

map(iris_with_missing, ~sum(is.na(.))) #check number of NAs before using map function
map(iris_without_missing, ~sum(is.na(.))) # ..and after using map function
```

